
* FPUS23
#+begin_src python :tangle ~/projects/ultrasound/fpus23/fpus23.py :mkdirp yes :ignore
import os
import numpy as np
import cv2
from segment_anything import sam_model_registry, SamPredictor
from xml.etree import ElementTree as ET
import matplotlib.pyplot as plt
from PIL import Image

os.environ.pop("QT_QPA_PLATFORM_PLUGIN_PATH")

def show_box(box, ax):
    x0, y0 = box[0], box[1]
    w, h = box[2] - box[0], box[3] - box[1]
    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2)) 

def show_mask(mask, ax, random_color=False):
    if random_color:
        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)
    else:
        color = np.array([30/255, 144/255, 255/255, 0.6])
    h, w = mask.shape[-2:]
    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)
    ax.imshow(mask_image)

model_type="vit_b"
sam_ckpt="/home/lfz/projects/ultrasound/weights/sam_vit_b.pth"
sam = sam_model_registry[model_type](checkpoint=sam_ckpt)
predictor = SamPredictor(sam)
print("Pretrained SAM loaded!")

ano_path = "/home/lfz/projects/ultrasound/data/fpus23/Dataset/boxes/annotation"
img_path = "/home/lfz/projects/ultrasound/data/fpus23/Dataset/four_poses"

bbox = []
X = []
Y = []
la = []
LA = []

# Scan all xml files for labels and image names
for obj in os.listdir(ano_path):
    file_name = os.path.join(ano_path, obj, 'annotations.xml')
    dom = ET.parse(file_name)

    names = dom.findall('image')
    for n in names:
        bbox = []
        la = []
        name = n.attrib.get('name')
        lab = n.findall('box')
        
        if not (lab == []):
            for l in lab:
                xtl = l.attrib.get('xtl')
                ytl = l.attrib.get('ytl')
                xbr = l.attrib.get('xbr')
                ybr = l.attrib.get('ybr')
                label = l.attrib.get('label')
                box = [xtl, ytl, xbr, ybr]

                if label == 'head':
                    la.append(1)
                elif label == 'abdomen':
                    la.append(2)
                elif label == 'arm':
                    la.append(3)
                elif label == 'legs':
                    la.append(4)

                bbox.append(box)
            x = os.path.join(img_path, obj,name)
            Y.append(bbox)
            X.append(x)
            LA.append(la)

print(len(X), len(Y), len(LA))
for idx,img_name in enumerate(X):
    print(img_name)
    img = cv2.imread(img_name)
    img_res = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)#.astype(np.float32)
    predictor.set_image(img)
    # diving by 255
    # img_res /= 255.0

    # cv2 image gives size as height x width
    wt = img.shape[1]
    ht = img.shape[0]

    labels = LA[idx]
    boxes = Y[idx]
    boxes = np.array(boxes).astype(float)

    bmp_path = img_name.replace("four_poses", "masks")
    bmp_path = bmp_path.replace("png", "bmp")
    # bmp_folder = "/".join(bmp_path.split("/")[:-1])
    bmp_folder = bmp_path[:-4]
    os.makedirs(bmp_folder, exist_ok=True)

    # overlay_path = img_name.replace("four_poses", "overlay")
    # overlay_folder = "/".join(overlay_path.split("/")[:-1])
    # os.makedirs(overlay_folder, exist_ok=True)
    # plt.imshow(img)
    for i,box in enumerate(boxes):
        masks, _, _ = predictor.predict(
            point_coords=None,
            point_labels=None,
            box=box[None, :],
            multimask_output=False,
        )
        mask = masks[0]
        la = labels[i]
        # show_box(box, plt.gca())

        image_bmp = Image.fromarray(mask)
        bmp_path = os.path.join(bmp_folder,f"{i}_{la}.bmp")
        image_bmp.save(bmp_path, format='BMP')

    # show_mask(mask, plt.gca())
    # plt.savefig(overlay_path, bbox_inches='tight')
    # plt.close()
    # break
#+end_src
