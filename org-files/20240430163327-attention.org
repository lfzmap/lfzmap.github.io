:PROPERTIES:
:ID:       f9a2bb31-aad5-452c-90f0-7b24c7cd1ac4
:END:
#+title: Attention

* Seq2Seq models

[[./img/seq2seq.gif]]

Applications include machine translation, text summarization, and image captioning.
Under the hood seq2seq is a encoder-decoder architecture, where encoder pass a vector named *Context* to decoder.

[[./img/seq2seq2.gif]]

Encoder and Decoder models tend to be [[id:e6912603-7852-4359-847c-d14008e9045e][Recurrent neural network]] usually.

[[./img/rnn.gif]]

At a time an RNN encoder takes two inputs:
1. input vector
2. hidden state

In seq2seq input is a word, so we use word embedding algorithms to convert a word into a vector.


[[./img/wordembed.png]]

Letâ€™s look at the hidden states for the encoder. Notice how the last hidden state is actually the context we pass along to the decoder.

[[./img/seq2seq3.gif]]

The context vector becomes a bottleneck hence Attention.

* Attention models

Attention models pass all hidden states from the encoder to the decoder.

[[./img/seq2seq4.gif]]

At the decoder side it does an extra step in the calculation of the hidden state.

[[./img/attention.gif]]

[[./img/attention2.gif]]

1. The attention decoder RNN takes in the embedding of the <END> token, and an initial decoder hidden state.
2. The RNN processes its inputs, producing an output and a new hidden state vector (h4). The output is discarded.
3. Attention Step: We use the encoder hidden states and the h4 vector to calculate a context vector (C4) for this time step.
4. We concatenate h4 and C4 into one vector.
5. We pass this vector through a feedforward neural network (one trained jointly with the model).
6. The output of the feedforward neural networks indicates the output word of this time step.
7. Repeat for the next time steps

   [[./img/attention3.gif]]
